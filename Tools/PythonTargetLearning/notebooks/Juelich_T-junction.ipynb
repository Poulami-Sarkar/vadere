{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as matplot\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from os import listdir, mkdir\n",
    "from os.path import join, isdir\n",
    "from ipywidgets import *\n",
    "from multiprocessing import Pool, Lock\n",
    "\n",
    "import nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../python/python_src_preprocessing/src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import utils.writer.density as density\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "LOGGING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def log(*args):\n",
    "    if LOGGING:\n",
    "        print(*args)\n",
    "\n",
    "def load_experiment(folder, key):\n",
    "    files = list(filter(lambda file: key in file, listdir(folder)))\n",
    "    \n",
    "    if len(files) == 0:\n",
    "        return None\n",
    "    \n",
    "    data = pd.read_csv(\n",
    "        join(folder, files[0]), \n",
    "        sep=' ', \n",
    "        names=['p-id', 'timestep', 'x', 'y', 'e'], \n",
    "        index_col=False, \n",
    "        header=None, \n",
    "        skiprows=0)\n",
    "        \n",
    "    data['x'] = data['x'] / 100\n",
    "    data['y'] = data['y'] / 100\n",
    "    \n",
    "    print('loaded', files[0])\n",
    "    \n",
    "    return files[0], data\n",
    "    \n",
    "def load_multiple(path, folders, key):\n",
    "    frames = []\n",
    "    for folder in folders:\n",
    "        frames.append(load_experiment(join(path, folder), key))\n",
    "            \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_experiment(frame, title):\n",
    "    fig, ax = matplot.subplots()\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # map p-ids to targets\n",
    "    for pId, group in frame.groupby('p-id'):\n",
    "        ax.plot(group['x'], group['y'])\n",
    "    \n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extract_observation_area(frame, area):\n",
    "    is_x = (frame['x'] >= area[0]) & (frame['x'] <= (area[0] + area[2]))\n",
    "    is_y = (frame['y'] >= area[1]) & (frame['y'] <= (area[1] + area[3]))\n",
    "    return frame[is_x & is_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_target_percentiles(pedestrians, ped2target, targets):\n",
    "    if len(pedestrians)== 0:\n",
    "        return None\n",
    "    \n",
    "    ids = list(pedestrians['p-id'])\n",
    "    total = len(ids)\n",
    "    \n",
    "    filtered_dict = {k:v for k,v in ped2target.items() if k in ids}\n",
    "    used_targets = filtered_dict.values()\n",
    "    \n",
    "    percentiles = {k:(len(list(v)) / total) for k, v in itertools.groupby(sorted(used_targets))}\n",
    "    \n",
    "    for k in targets:\n",
    "        if k not in used_targets:\n",
    "            percentiles[k] = 0.0\n",
    "    \n",
    "    return percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_gaussian_grid(gauss_bound, resolution, sigma, ped_pos, radius):\n",
    "    x = np.arange(-gauss_bound, gauss_bound + resolution, resolution) # gives gauss_bound_start:resolution:gauss_bound_stop\n",
    "    \n",
    "    xx, yy = np.meshgrid(x, x, sparse=False) # Make all grid points (based on resolution) in [gauss_bound_start, gauss_bound_stop] (2-dim-array)\n",
    "        \n",
    "    grid = np.sqrt(np.square(xx-ped_pos[0]) + np.square(yy-ped_pos[1])) # distance to the origin of the observation area\n",
    "    \n",
    "    gauss = np.vectorize(gaussian_pdf)\n",
    "\n",
    "    gauss_grid = gauss(sigma, grid, radius)\n",
    "    \n",
    "    return gauss_grid\n",
    "\n",
    "\n",
    "def gaussian_pdf(sigma, x, radius ):\n",
    "    zaehler = ((radius*2)**2) * np.sqrt(3)  # S_p\n",
    "    nenner = 2 * 2 * np.pi * (sigma**2)\n",
    "\n",
    "    normalization_factor = zaehler/nenner\n",
    "    individual_density = normalization_factor * np.exp(-x / (2 * np.square(sigma)))\n",
    "\n",
    "    return individual_density\n",
    "\n",
    "\n",
    "def add_pedestrian_to_field(ped, matrix, area, resolution, gauss_density_bound, sigma, ped_radius, general_density_matrix):\n",
    "    if general_density_matrix is None: # not None\n",
    "        bool_individual_position = True\n",
    "    else:\n",
    "        bool_individual_position = False\n",
    "\n",
    "    # calculate the density for one ped and add to matrix\n",
    "    size = int(gauss_density_bound * 2 / resolution + 1)\n",
    "    radius = int(size / 2) # equal to gauss_density_bound/resolution\n",
    "    log('size', size, 'radius', radius)\n",
    "    \n",
    "    origin_x = area[0]\n",
    "    origin_y = area[1]\n",
    "    log('origin x', origin_x, 'origin y', origin_y)\n",
    "    \n",
    "    width = int(area[2] / resolution)\n",
    "    height = int(area[3] / resolution)\n",
    "    log('width', width, 'height', height)\n",
    "    \n",
    "    \n",
    "    # necessary to map to center of the grid instead of the edge!\n",
    "    offset = resolution / 2\n",
    "    log('offset', offset)\n",
    "    \n",
    "    \n",
    "    # find grid cell of pedestrian in observation area\n",
    "    diff_x = int(np.round((ped['x'] - origin_x - offset) / resolution, 0))\n",
    "    diff_y = int(np.round((ped['y'] - origin_y - offset) / resolution, 0))\n",
    "\n",
    "    log('diff x', diff_x, 'diff y', diff_y)\n",
    "    \n",
    "    # area in which the pedestrian has an influence on the pedestrian density\n",
    "    left_bound = int(max(0, diff_x - radius))\n",
    "    right_bound = int(min(diff_x + radius, width - 1))\n",
    "    upper_bound = int(min(diff_y + radius, height - 1))\n",
    "    lower_bound = int(max(0, diff_y - radius))\n",
    "    \n",
    "    log('left', left_bound, 'right', right_bound)\n",
    "    log('upper', upper_bound, 'lower', lower_bound)\n",
    "\n",
    "    ## create density_field\n",
    "    # position of pedestrian relative to center of grid cell\n",
    "    grid_points_x = np.arange(origin_x+offset, origin_x + area[2] + resolution, resolution) # gives gauss_bound_start:resolution:gauss_bound_stop\n",
    "    grid_points_y = np.arange(origin_y+offset, origin_y + area[3] + resolution, resolution)\n",
    "\n",
    "    # center of cell in which the pedestrian is located\n",
    "    grid_point_x = grid_points_x[diff_x]\n",
    "    grid_point_y = grid_points_y[diff_y]\n",
    "\n",
    "    ped_pos_rel_x = ped['x'] - grid_point_x\n",
    "    ped_pos_rel_y = ped['y'] - grid_point_y\n",
    "\n",
    "    log(ped_pos_rel_x, ped_pos_rel_y)\n",
    "    \n",
    "    # Position of pedestrian relative to cell center\n",
    "    ped_pos_rel = np.array([ped_pos_rel_x, ped_pos_rel_y])\n",
    "\n",
    "    log(bool_individual_position)\n",
    "    \n",
    "    if bool_individual_position:\n",
    "        density_field = get_gaussian_grid(gauss_density_bound, resolution, sigma, ped_pos_rel, ped_radius)\n",
    "    else:\n",
    "        density_field = general_density_matrix\n",
    "    \n",
    "    '''\n",
    "    fig, ax = matplot.subplots()\n",
    "    img = ax.imshow(density_field, interpolation='Nearest')\n",
    "    fig.colorbar(img)\n",
    "    '''\n",
    "    \n",
    "    # cutout of density field that is within the camera cutout\n",
    "    left_bound_field = max(0, radius - diff_x)\n",
    "    right_bound_field = left_bound_field + right_bound - left_bound\n",
    "\n",
    "    lower_bound_field = max(0, radius - diff_y)\n",
    "    upper_bound_field = lower_bound_field + upper_bound - lower_bound\n",
    "\n",
    "    matrix[lower_bound:upper_bound+1, left_bound:right_bound+1] = \\\n",
    "        matrix[lower_bound:upper_bound+1, left_bound:right_bound+1] + density_field[lower_bound_field:upper_bound_field+1, left_bound_field:right_bound_field+1]\n",
    "\n",
    "    return matrix\n",
    "    \n",
    "\n",
    "def get_density_field(pedestrians, context):\n",
    "    density_field = context.get('density_field', None)\n",
    "    \n",
    "    if density_field is not None:\n",
    "        print(density_field)\n",
    "    \n",
    "    size = context.get('size', (0, 0))\n",
    "    \n",
    "    density_approx = np.zeros(size)\n",
    "    ped_list = np.zeros([len(pedestrians),2])\n",
    "    \n",
    "    idx = 0\n",
    "    for _, pedestrian in pedestrians.iterrows():\n",
    "        density_approx = add_pedestrian_to_field(\n",
    "            pedestrian, \n",
    "            density_approx, \n",
    "            context.get('area', None), \n",
    "            context.get('resolution', 1), \n",
    "            context.get('gauss_bounds', 1), \n",
    "            context.get('sigma', 0.7),\n",
    "            context.get('pedestrian_radius', 0.195),\n",
    "            density_field)\n",
    "\n",
    "        ped_list[idx,:] = [pedestrian['x'], pedestrian['y']]\n",
    "        idx += 1\n",
    "        \n",
    "\n",
    "    return density_approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_percentiles(pedestrians, percentiles, density, context):\n",
    "    data = context.get('percentiles', None)\n",
    "    \n",
    "    # create dataframe if not yet available\n",
    "    if data is None:\n",
    "        data = pd.DataFrame(columns=context.get('targets'))\n",
    "    \n",
    "    context['percentiles'] = data.append(percentiles, ignore_index=True)\n",
    "    \n",
    "    return context\n",
    "\n",
    "def process_pedestrians(pedestrians, percentiles, density, context):\n",
    "    data = context.get('pedestrians', None)\n",
    "    \n",
    "    # create dataframe if not yet available\n",
    "    if data is None:\n",
    "        data = []\n",
    "    \n",
    "    data.append(pedestrians)\n",
    "    \n",
    "    context['pedestrians'] = data\n",
    "    \n",
    "    return context\n",
    "    \n",
    "    \n",
    "def process_peds_per_step(pedestrians, percentiles, density, context):\n",
    "    data = context.get('pedestrians', None)\n",
    "    \n",
    "    # create dataframe if not yet available\n",
    "    if data is None:\n",
    "        data = pd.DataFrame(columns=['#peds'])\n",
    "        \n",
    "    context['pedestrians'] = data.append({'#peds': len(peds) }, ignore_index=True)\n",
    "    \n",
    "    return context\n",
    "    \n",
    "    \n",
    "def process_densities(pedestrians, percentiles, density, context):\n",
    "    data = context.get('densities', None)\n",
    "    \n",
    "    # create dataframe if not yet available\n",
    "    if data is None:\n",
    "        data = []\n",
    "        context['densities'] = data\n",
    "    \n",
    "    distribution = [percentiles[key] for key in sorted(percentiles.keys())]\n",
    "    data.append(np.concatenate((density.flatten(), distribution), axis=None))\n",
    "    \n",
    "    return context\n",
    "\n",
    "'''\n",
    "def process_timestep(timestep, trajectories, context):\n",
    "    pedestrians = extract_observation_area(trajectories, area)\n",
    "        \n",
    "    # skip if empty area\n",
    "    if len(pedestrians) == 0:\n",
    "        return\n",
    "\n",
    "    percentiles = get_target_percentiles(pedestrians, pId2Target, context.get('targets', ['A', 'B']))\n",
    "\n",
    "    if percentiles['A'] == 0.5 and percentiles['B'] == 0.5:\n",
    "        flag = not(flag)\n",
    "        if flag:\n",
    "            return\n",
    "\n",
    "\n",
    "    density = get_density_field(pedestrians, context)\n",
    "\n",
    "    # execute processors\n",
    "    for processor in processors:\n",
    "        context = processor(pedestrians, percentiles, density, context)\n",
    "        \n",
    "def process_experiment(experiment, context):\n",
    "    name = context.get('name', '')\n",
    "    \n",
    "    processors = context.get('processors', None)\n",
    "    if processors is None or type(processors) != list:\n",
    "        processors = []\n",
    "    \n",
    "    pId2Target = dict.fromkeys(list(frame['p-id'].unique()))\n",
    "    \n",
    "    # map p-ids to targets\n",
    "    for pId, group in frame.groupby('p-id'):\n",
    "        pId2Target[pId] = ('B' if group['x'].iloc[0] < 0 else 'A')\n",
    "    \n",
    "    if not context.get('exact', False):\n",
    "        context['density_field'] = get_gaussian_grid(\n",
    "            context.get('gauss_bounds', 0),\n",
    "            context.get('resolution', 1),\n",
    "            context.get('sigma', 1),\n",
    "            [0, 0])\n",
    "    \n",
    "    area = context.get('area')\n",
    "    resolution = context.get('resolution')\n",
    "    \n",
    "    size = (int(area[3]/ resolution), int(area[2] / resolution))\n",
    "    context['size'] = size\n",
    "    context['pId2Target'] = pId2Target\n",
    "    \n",
    "    flag = True\n",
    "    \n",
    "    for timestep, trajectories in tqdm_notebook(frame.groupby('timestep'), desc=name, unit=' timestep'):\n",
    "        # extract #-of peds in observation area\n",
    "        pedestrians = extract_observation_area(trajectories, area)\n",
    "        \n",
    "        # skip if empty area\n",
    "        if len(pedestrians) == 0:\n",
    "            continue\n",
    "            \n",
    "        percentiles = get_target_percentiles(pedestrians, pId2Target, context.get('targets', ['A', 'B']))\n",
    "        \n",
    "        if percentiles['A'] == 0.5 and percentiles['B'] == 0.5:\n",
    "            flag = not(flag)\n",
    "            if flag:\n",
    "                continue\n",
    "            \n",
    "        \n",
    "        density = get_density_field(pedestrians, context)\n",
    "        \n",
    "        # execute processors\n",
    "        for processor in processors:\n",
    "            context = processor(pedestrians, percentiles, density, context)\n",
    "        \n",
    "        \n",
    "    return context\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_experiment(experiment, context):\n",
    "    name = context.get('name', '')\n",
    "    \n",
    "    processors = context.get('processors', None)\n",
    "    if processors is None or type(processors) != list:\n",
    "        processors = []\n",
    "    \n",
    "    pId2Target = dict.fromkeys(list(frame['p-id'].unique()))\n",
    "    \n",
    "    # map p-ids to targets\n",
    "    for pId, group in frame.groupby('p-id'):\n",
    "        pId2Target[pId] = ('B' if group['x'].iloc[0] < 0 else 'A')\n",
    "    \n",
    "    if not context.get('exact', False):\n",
    "        context['density_field'] = get_gaussian_grid(\n",
    "            context.get('gauss_bounds', 0),\n",
    "            context.get('resolution', 1),\n",
    "            context.get('sigma', 1),\n",
    "            [0, 0])\n",
    "    \n",
    "    area = context.get('area')\n",
    "    resolution = context.get('resolution')\n",
    "    \n",
    "    size = (int(area[3]/ resolution), int(area[2] / resolution))\n",
    "    context['size'] = size\n",
    "    context['pId2Target'] = pId2Target\n",
    "    \n",
    "    flag = True\n",
    "    \n",
    "    timesteps = list(experiment.groupby('timestep'))\n",
    "    total = len(timesteps)\n",
    "    timesteps = list(map(lambda a: (*a, context), timesteps))\n",
    "    \n",
    "    lock = Lock()\n",
    "    \n",
    "    with Pool(processes=4) as p:\n",
    "        with tqdm_notebook(total=total) as pbar:\n",
    "            for i, result in enumerate(p.imap_unordered(nothing.doNothing, timesteps)):\n",
    "                pbar.update()\n",
    "                \n",
    "                pedestrians, percentiles, density = result\n",
    "                \n",
    "                if pedestrians is None:\n",
    "                    continue\n",
    "                \n",
    "                \n",
    "                if percentiles['A'] == 0.5 and percentiles['B'] == 0.5:\n",
    "                    lock.acquire()\n",
    "                    flag = not(flag)\n",
    "                    lock.release()\n",
    "                    if flag:\n",
    "                        continue\n",
    "                    \n",
    "                # execute processors\n",
    "                lock.acquire()\n",
    "                for processor in processors:\n",
    "                    context = processor(pedestrians, percentiles, density, context)\n",
    "                lock.release()\n",
    "                    \n",
    "                \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_path = 'juelich/KO/'\n",
    "output_path = 'juelich/output_01/'\n",
    "experiments = [\n",
    "    'ko-240-050-240',\n",
    "    'ko-240-060-240',\n",
    "    'ko-240-080-240',\n",
    "    'ko-240-100-240',\n",
    "    'ko-240-120-240',\n",
    "    'ko-240-150-240',\n",
    "    'ko-240-240-240',\n",
    "    'ko-300-050-300',\n",
    "    'ko-300-080-300',\n",
    "    'ko-300-120-300',\n",
    "    'ko-300-150-300'\n",
    "]\n",
    "\n",
    "# frames = load_experiment(join(input_path, experiments[0]), 'combined')\n",
    "\n",
    "# frames = load_multiple(input_path, experiments, 'combined')\n",
    "\n",
    "if not isdir(output_path):\n",
    "    mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1c963c010e45ad8c415ad9b4215ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='process files', max=11, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ko-240-050-240_combined_MB.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:05<00:00, 168.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ko-240-060-240_combined_MB.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 942/942 [00:06<00:00, 154.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ko-240-080-240_combined_MB.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1157/1157 [00:11<00:00, 104.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ko-240-100-240_combined_MB.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1033/1033 [00:10<00:00, 100.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ko-240-120-240_combined_MB.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1511/1511 [00:16<00:00, 111.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ko-240-150-240_combined_MB.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1426/1426 [00:16<00:00, 87.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ko-240-240-240_combined_MB.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1414/1414 [00:16<00:00, 86.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ko-300-050-300_combined_MB.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1111/1111 [00:05<00:00, 202.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ko-300-080-300_combined_MB.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1112/1112 [00:07<00:00, 139.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ko-300-120-300_combined_MB.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1269/1269 [00:12<00:00, 97.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ko-300-150-300_combined_MB.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1240/1240 [00:13<00:00, 122.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor result in tqdm_notebook(results, desc=\\'saving density files\\'):\\n    name = result.get(\\'name\\')\\n    densities = result.get(\\'densities\\')\\n    \\n    with open(join(output_path, name + \\'.csv\\'), mode=\\'w\\') as file:\\n        for density in densities:\\n            file.write(\\';\\'.join(map(lambda r: \"{:.10f}\".format(r), density)) + \\'\\n\\')\\n        \\n        file.flush()\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nothing\n",
    "\n",
    "results = []\n",
    "for experiment in tqdm_notebook(experiments, desc='process files'):\n",
    "    # plot_experiment(frame, experiment)\n",
    "    filename, frame = load_experiment(join(input_path, experiment), 'combined')\n",
    "    name = filename[:filename.index('.')]\n",
    "    context = dict({\n",
    "        'name': name,\n",
    "        'targets': ['A', 'B', 'C'],\n",
    "        'area':  [-2.4, 3, 2.4, 1],\n",
    "        'exact': True,\n",
    "        'sigma': 0.7,\n",
    "        'resolution': 0.1,\n",
    "        'pedestrian_radius': 0.195,\n",
    "        'gauss_bounds': 2,\n",
    "        'processors': [\n",
    "            nothing.process_densities\n",
    "        ]\n",
    "    })\n",
    "    context = nothing.process_experiment(frame, context)\n",
    "    results.append(context)\n",
    "    \n",
    "    densities = context.get('densities')\n",
    "    with open(join(output_path, name + '.csv'), mode='w') as file:\n",
    "        for density in densities:\n",
    "            file.write(';'.join(map(lambda r: \"{:.10f}\".format(r), density)) + '\\n')\n",
    "        \n",
    "        file.flush()\n",
    "    \n",
    "    \n",
    "'''\n",
    "for result in tqdm_notebook(results, desc='saving density files'):\n",
    "    name = result.get('name')\n",
    "    densities = result.get('densities')\n",
    "    \n",
    "    with open(join(output_path, name + '.csv'), mode='w') as file:\n",
    "        for density in densities:\n",
    "            file.write(';'.join(map(lambda r: \"{:.10f}\".format(r), density)) + '\\n')\n",
    "        \n",
    "        file.flush()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extrac_xy(pedestrians, x0, y0, resolution):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for _, ped in pedestrians.iterrows():\n",
    "        x.append(int(abs(ped['x'] - x0) * ( 1 / resolution)))\n",
    "        y.append(int(abs(ped['y'] - y0) * ( 1 / resolution)))\n",
    "    \n",
    "    return x, y\n",
    "        \n",
    "\n",
    "for result in tqdm_notebook(results, desc='process results'):\n",
    "    name = result.get('name')\n",
    "    densities = result.get('densities')\n",
    "    area = context.get('area')\n",
    "    peds = context.get('pedestrians')\n",
    "    size = result.get('size')\n",
    "    res = result.get('resolution')\n",
    "    \n",
    "    start = 12\n",
    "    \n",
    "    first = densities[start][:-3].reshape(size)\n",
    "    #first = first / np.max(first)\n",
    "    \n",
    "    fig, ax = matplot.subplots()\n",
    "    \n",
    "    #img = ax.imshow(first, interpolation='Nearest')\n",
    "    cbar = None #fig.colorbar(img)\n",
    "    \n",
    "    #x, y = extrac_xy(peds[0], area[0], area[1], res)\n",
    "\n",
    "    #pl = ax.plot(x, y, '.r', markersize=10)\n",
    "    \n",
    "    ax.set_xticks(np.linspace(0, len(first[0]) - 1, 13))\n",
    "    ax.set_xticklabels([0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 2.2, 2.4])\n",
    "    \n",
    "    ax.set_yticks(np.linspace(0, len(first) - 1, 6))\n",
    "    ax.set_yticklabels([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    def update(frame):\n",
    "        global cbar\n",
    "        f = densities[frame][:-3].reshape(size)\n",
    "        \n",
    "        ax.clear()\n",
    "        if cbar is not None:\n",
    "            cbar.remove()\n",
    "        \n",
    "        img = ax.imshow(f, interpolation='Nearest')\n",
    "        cbar = fig.colorbar(img)\n",
    "\n",
    "        x, y = extrac_xy(peds[frame], area[0], area[1], res)\n",
    "        print(list(zip(x, y)))\n",
    "        ax.plot(x, y, '.r', markersize=10)\n",
    "\n",
    "        ax.set_xticks(np.linspace(0, len(first[0]) - 1, 13))\n",
    "        ax.set_xticklabels([0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 2.2, 2.4])\n",
    "\n",
    "        ax.set_yticks(np.linspace(0, len(first) - 1, 6))\n",
    "        ax.set_yticklabels([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "        \n",
    "\n",
    "    interact(update, frame=widgets.IntSlider(min=0, max=len(densities)-1, step=1, value=start));\n",
    "    \n",
    "    break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "percentiles = pd.concat([result['percentiles'] for result in results])\n",
    "display(percentiles.groupby(result.get('targets'), as_index=False).size().to_frame('frames').reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def gaussian(R, x, z):\n",
    "    a = 1 / (2 * np.pi * (R**2))\n",
    "    b = -1 / (2 * (R**2))\n",
    "    \n",
    "    return a * math.exp(b * (np.linalg.norm(np.array(x) - np.array(z))**2))\n",
    "\n",
    "def density(pedestrians, z, R, g):\n",
    "    S_p = g**2 * math.sqrt(3) / 2\n",
    "    D_p = S_p * np.sum(list(map(lambda x: gaussian(R, x, z) ,pedestrians)))\n",
    "    \n",
    "    return D_p\n",
    "\n",
    "def generate(points):\n",
    "    x = np.arange(-1, 1 + 0.1, 0.1)\n",
    "    y = np.arange(-1, 1 + 0.1, 0.1)\n",
    "\n",
    "    xx, yy = np.meshgrid(x, y, sparse=False)\n",
    "\n",
    "    matrix = np.zeros((len(y), len(x)))\n",
    "    if len(points) > 0:\n",
    "        for i in range(0, len(y)):\n",
    "            for j in range(0, len(x)):\n",
    "                matrix[i, j] = density(points, [xx[i, j], yy[i, j]], 0.7, 0.195)\n",
    "            \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A = generate([[0.45, 0]])\n",
    "B = generate([[-0.8, 0]])\n",
    "\n",
    "C = np.zeros((10, 24))\n",
    "\n",
    "'''\n",
    "C[:, 6:22] = C[:, 6:22] + A[:, 6:22]\n",
    "C[:, 0:10] = C[:, 0:10] + B[:, 0:10]\n",
    "'''\n",
    "\n",
    "fig, ax = matplot.subplots()\n",
    "img = ax.imshow(A)\n",
    "fig.colorbar(img)\n",
    "\n",
    "fig, ax = matplot.subplots()\n",
    "img = ax.imshow(B)\n",
    "fig.colorbar(img)\n",
    "\n",
    "'''\n",
    "fig, ax = matplot.subplots()\n",
    "img = ax.imshow(A, vmin=0, vmax=0.011)\n",
    "fig.colorbar(img)\n",
    "'''\n",
    "\n",
    "fig, ax = matplot.subplots()\n",
    "img = ax.imshow(C)\n",
    "fig.colorbar(img)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# A = generate([[-0.8, 0]])\n",
    "# B = generate([[0.8, 0]])\n",
    "y = int(1 / 0.1)\n",
    "x = int(2.4 / 0.1)\n",
    "\n",
    "matrix = np.zeros((y, x))\n",
    "add_pedestrian_to_field({'x': -0.75, 'y': 3.5}, matrix, [-2.4, 3, 2.4, 1], 0.1, .5, 0.7, 0.195, None)\n",
    "add_pedestrian_to_field({'x': -2, 'y': 3.5}, matrix, [-2.4, 3, 2.4, 1], 0.1, .5, 0.7, 0.195, None)\n",
    "\n",
    "fig, ax = matplot.subplots()\n",
    "img = ax.imshow(matrix)\n",
    "fig.colorbar(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A = get_gaussian_grid(1, .1, 0.7, [-0, 0.04999999999999982], 0.195)\n",
    "\n",
    "fig, ax = matplot.subplots()\n",
    "img = ax.imshow(A)\n",
    "fig.colorbar(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
