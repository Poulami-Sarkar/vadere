{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Search-trajectory-files-and-create-output-path\" data-toc-modified-id=\"Search-trajectory-files-and-create-output-path-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Search trajectory files and create output path</a></span></li><li><span><a href=\"#Plot-experiment-trajectories\" data-toc-modified-id=\"Plot-experiment-trajectories-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Plot experiment trajectories</a></span></li><li><span><a href=\"#Processing-Experiments\" data-toc-modified-id=\"Processing-Experiments-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Processing Experiments</a></span></li><li><span><a href=\"#Interactive-plot-of-density-images\" data-toc-modified-id=\"Interactive-plot-of-density-images-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Interactive plot of density images</a></span></li><li><span><a href=\"#Aggregate-unfiltered-density-distributions\" data-toc-modified-id=\"Aggregate-unfiltered-density-distributions-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Aggregate unfiltered density distributions</a></span></li><li><span><a href=\"#Filter-50/50-distributions\" data-toc-modified-id=\"Filter-50/50-distributions-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Filter 50/50 distributions</a></span></li><li><span><a href=\"#Aggregate-filtered-density-distributions\" data-toc-modified-id=\"Aggregate-filtered-density-distributions-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Aggregate filtered density distributions</a></span></li><li><span><a href=\"#Plot-density-maps-to-file\" data-toc-modified-id=\"Plot-density-maps-to-file-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Plot density maps to file</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T17:04:27.007689Z",
     "start_time": "2019-09-25T17:04:26.482177Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as matplot\n",
    "import itertools\n",
    "import math\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from os import listdir, mkdir\n",
    "from os.path import join, isdir\n",
    "from ipywidgets import *\n",
    "from multiprocessing import Pool, Lock\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../python/python_src_preprocessing/target_learning'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import preprocessing.preprocessing as processing\n",
    "import plotting.densitymap as plot\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport preprocessing.preprocessing, plotting.densitymap\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search trajectory files and create output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T09:15:17.218936Z",
     "start_time": "2019-09-24T09:15:17.214940Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# paramter\n",
    "input_path = 'datasets/KO/'\n",
    "output_path = 'check/240x200/csvs/experiment'\n",
    "experiments = [\n",
    "    'ko-240-050-240',\n",
    "    'ko-240-060-240',\n",
    "    'ko-240-080-240',\n",
    "    'ko-240-100-240',\n",
    "    'ko-240-120-240',\n",
    "    'ko-240-150-240',\n",
    "    'ko-240-240-240',\n",
    "    # 'ko-300-050-300',\n",
    "    # 'ko-300-080-300',\n",
    "    # 'ko-300-120-300',\n",
    "    # 'ko-300-150-300'\n",
    "]\n",
    "\n",
    "if not isdir(output_path):\n",
    "    mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T09:15:19.433980Z",
     "start_time": "2019-09-24T09:15:19.425973Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def toInch(pixel, dpi=92):\n",
    "    return pixel / dpi\n",
    "\n",
    "\n",
    "def plot_experiment(frame, ax):\n",
    "    # map p-ids to targets\n",
    "    for pId, group in frame.groupby('pedestrianId'):\n",
    "        ax.plot(group['x'], group['y'], zorder=1)\n",
    "\n",
    "    rect = matplot.Rectangle(\n",
    "        (-2.4, 3), 2.4, 1, edgecolor='r', alpha=1, fill=False, zorder=2, linewidth=2)\n",
    "\n",
    "    ax.add_patch(rect)\n",
    "    ax.grid()\n",
    "    \n",
    "\n",
    "def load_experiment(folder, key):\n",
    "    files = list(filter(lambda file: key in file, listdir(folder)))\n",
    "    \n",
    "    if len(files) == 0:\n",
    "        return None\n",
    "    \n",
    "    data = pd.read_csv(\n",
    "        join(folder, files[0]), \n",
    "        sep=' ', \n",
    "        names=['pedestrianId', 'timeStep', 'x', 'y'], \n",
    "        index_col=False, \n",
    "        header=None, \n",
    "        skiprows=0)\n",
    "        \n",
    "    data.x = data.x / 100\n",
    "    data.y = data.y / 100\n",
    "    \n",
    "    print('loaded', files[0])\n",
    "    \n",
    "    return files[0], data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot experiment trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot all scenario trajectories to file\n",
    "plots = len(experiments)\n",
    "rows = math.ceil(plots / 2.0)\n",
    "fig, ax = matplot.subplots(nrows=rows, ncols=2, figsize=(\n",
    "    toInch(1000), toInch(rows * 300)), dpi=92)\n",
    "\n",
    "ax = np.array(ax).flatten()\n",
    "\n",
    "for idx in range(plots):\n",
    "    experiment = experiments[idx]\n",
    "    ax[idx].set_title(experiment)\n",
    "\n",
    "    _, frame = load_experiment(join(input_path, experiment), 'combined')\n",
    "    plot_experiment(frame, ax[idx])\n",
    "\n",
    "fig.subplots_adjust(hspace=0.25)\n",
    "fig.savefig('experiment-scenario-trajectories.pdf', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T14:30:42.148290Z",
     "start_time": "2019-09-21T14:19:53.942412Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# processing experiments\n",
    "\n",
    "results = []\n",
    "for experiment in tqdm_notebook(experiments, desc='process files'):\n",
    "    directory = os.path.dirname(experiment)\n",
    "    \n",
    "    filename, frame = load_experiment(join(input_path, experiment), 'combined')\n",
    "    name = experiment # filename[:filename.index('.')]\n",
    "    \n",
    "    if os.path.exists(join(output_path, name + '.csv')):\n",
    "        print('skipping', name)\n",
    "        continue\n",
    "    \n",
    "    context = dict({\n",
    "        'name': name,\n",
    "        'targets': ['A', 'B'],\n",
    "        'area':  [-2.4, 2, 2.4, 2],\n",
    "        'exact': True,\n",
    "        'sigma': 0.7,\n",
    "        'resolution': 0.1,\n",
    "        'pedestrian_radius': 0.195,\n",
    "        'gauss_bounds': 2,\n",
    "        'pId2Target': processing.juelich_assign_target,\n",
    "        'filters': [\n",
    "            # preprocessing.juelich_filter_percentiles,\n",
    "        ],\n",
    "        'processors': [\n",
    "            processing.process_densities,\n",
    "            processing.process_pedestrians,\n",
    "            processing.process_percentiles\n",
    "        ],\n",
    "        'number_of_cores': 5,\n",
    "        'skip': 1,\n",
    "        'timesteps': join(input_path, experiment, 'timesteps')\n",
    "    })\n",
    "    context = processing.process_experiment(frame, context)\n",
    "    results.append(context)\n",
    "\n",
    "    densities = np.array(context.get('densities'))\n",
    "    if densities is None:\n",
    "        # continue\n",
    "        break\n",
    "        \n",
    "    # sort densities by timestep number\n",
    "    densities = densities[densities[:,0].argsort()]\n",
    "    with open(join(output_path, name + '.csv'), mode='w') as file:\n",
    "        for density in densities:\n",
    "            file.write(\n",
    "                ';'.join(map(lambda r: \"{:.10f}\".format(r), density[1:])) + '\\n')\n",
    "\n",
    "        file.flush()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive plot of density images\n",
    "<font color='red' size='5'><b>Important note:</b><br/>This requires that the result of the processed files (cell above) is still available</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     3,
     7,
     13
    ]
   },
   "outputs": [],
   "source": [
    "# interactive density maps\n",
    "%matplotlib notebook\n",
    "\n",
    "def extrac_xy(pedestrians, x0, y0, resolution):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for _, ped in pedestrians.iterrows():\n",
    "        x.append(int(abs(ped['x'] - x0) * (1 / resolution)))\n",
    "        y.append(int(abs(ped['y'] - y0) * (1 / resolution)))\n",
    "\n",
    "    return x, y\n",
    "\n",
    "for result in results:\n",
    "    name = result.get('name')\n",
    "    densities = result.get('densities')\n",
    "    area = result.get('area')\n",
    "    peds = result.get('pedestrians')\n",
    "    size = result.get('size')\n",
    "    res = result.get('resolution')\n",
    "    t = len(result.get('targets'))\n",
    "\n",
    "    start = 0\n",
    "\n",
    "    first = densities[start][:-t].reshape(size)\n",
    "\n",
    "    fig, ax = matplot.subplots()\n",
    "\n",
    "    cbar = None\n",
    "\n",
    "    ax.set_xticks(np.linspace(0, len(first[0]) - 1, 13))\n",
    "    ax.set_xticklabels([0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2,\n",
    "                        1.4, 1.6, 1.8, 2.0, 2.2, 2.4])\n",
    "\n",
    "    ax.set_yticks(np.linspace(0, len(first) - 1, 6))\n",
    "    ax.set_yticklabels([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "\n",
    "    def update(frame):\n",
    "        global cbar\n",
    "        f = densities[frame][:-t].reshape(size)\n",
    "\n",
    "        ax.clear()\n",
    "        if cbar is not None:\n",
    "            cbar.remove()\n",
    "\n",
    "        img = ax.imshow(f, interpolation='Nearest')\n",
    "        cbar = fig.colorbar(img)\n",
    "\n",
    "        x, y = extrac_xy(peds[frame], area[0], area[1], res)\n",
    "\n",
    "        ax.plot(x, y, '.r', markersize=10)\n",
    "\n",
    "        ax.set_xticks(np.linspace(0, len(first[0]) - 1, 13))\n",
    "        ax.set_xticklabels([0, 0.2, 0.4, 0.6, 0.8, 1.0,\n",
    "                            1.2, 1.4, 1.6, 1.8, 2.0, 2.2, 2.4])\n",
    "\n",
    "        ax.set_yticks(np.linspace(0, len(first) - 1, 6))\n",
    "        ax.set_yticklabels([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "\n",
    "    interact(update, frame=widgets.IntSlider(\n",
    "        min=0, max=len(densities)-1, step=1, value=start))\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate unfiltered density distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T14:43:52.129817Z",
     "start_time": "2019-09-21T14:43:50.885615Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# aggregate distributions\n",
    "\n",
    "\n",
    "# output_p = 'juelich-vadere/output_01_save/'\n",
    "outputs = list(filter(lambda o: os.path.isfile(os.path.join(output_path, o)), os.listdir(output_path)))\n",
    "dfs = []\n",
    "for output in tqdm_notebook(outputs, desc=\"loading output files\", total=len(outputs)):\n",
    "    dfs.append(pd.read_csv(os.path.join(\n",
    "        output_path, output), sep=';', header=None))\n",
    "\n",
    "frame = pd.concat([df.iloc[:, -2:] for df in dfs], sort=False)\n",
    "display(frame.groupby(list(frame.columns), as_index=False).size().to_frame(\n",
    "    'frames').reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter 50/50 distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-21T14:46:18.149474Z",
     "start_time": "2019-09-21T14:46:17.541923Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filter every second 50% 50% distribution\n",
    "\n",
    "outputs = list(filter(lambda o: os.path.isfile(os.path.join(output_path, o)), os.listdir(output_path)))\n",
    "\n",
    "if not os.path.isdir(os.path.join(output_path, 'filtered')):\n",
    "    os.makedirs(os.path.join(output_path, 'filtered'))\n",
    "\n",
    "for output in tqdm_notebook(outputs, desc=\"filter density distributions\"):\n",
    "    skip = True\n",
    "    skipped = 0\n",
    "    written = 0\n",
    "    with open(os.path.join(output_path, output), \"r\") as full:\n",
    "        with open(os.path.join(output_path, 'filtered', output), \"w\") as filtered:\n",
    "            for line in full:\n",
    "                if line.strip().endswith('0.5000000000;0.5000000000'):\n",
    "                    skip = not(skip)\n",
    "                    \n",
    "                    if skip:\n",
    "                        skipped = skipped + 1\n",
    "                        continue\n",
    "                \n",
    "                filtered.write(line)\n",
    "                written = written + 1\n",
    "\n",
    "    print(written, 'lines written,', skipped, 'lines skipped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate filtered density distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T17:08:35.800457Z",
     "start_time": "2019-09-25T17:08:35.217930Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2934c1e0b26f42ee8b9942c96486fefb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='loading output files', max=7, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(7221, 2)\n",
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &       240 &       241 &  frames \\\\\n",
      "\\midrule\n",
      "0  &  0.000000 &  1.000000 &    1372 \\\\\n",
      "1  &  0.166667 &  0.833333 &      11 \\\\\n",
      "2  &  0.200000 &  0.800000 &      45 \\\\\n",
      "3  &  0.250000 &  0.750000 &     294 \\\\\n",
      "4  &  0.285714 &  0.714286 &       3 \\\\\n",
      "5  &  0.333333 &  0.666667 &     881 \\\\\n",
      "6  &  0.400000 &  0.600000 &     517 \\\\\n",
      "7  &  0.428571 &  0.571429 &      20 \\\\\n",
      "8  &  0.500000 &  0.500000 &    2241 \\\\\n",
      "9  &  0.571429 &  0.428571 &      23 \\\\\n",
      "10 &  0.600000 &  0.400000 &     471 \\\\\n",
      "11 &  0.625000 &  0.375000 &       2 \\\\\n",
      "12 &  0.666667 &  0.333333 &     838 \\\\\n",
      "13 &  0.714286 &  0.285714 &       2 \\\\\n",
      "14 &  0.750000 &  0.250000 &     304 \\\\\n",
      "15 &  0.800000 &  0.200000 &      35 \\\\\n",
      "16 &  1.000000 &  0.000000 &     738 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# aggregate distributions\n",
    "\n",
    "# output_p = 'juelich-vadere/output_01_save/'\n",
    "output_path = 'check/240x100/csvs/experiment'\n",
    "outputs = os.listdir(os.path.join(output_path, 'filtered'))\n",
    "dfs = []\n",
    "for output in tqdm_notebook(outputs, desc=\"loading output files\", total=len(outputs)):\n",
    "    dfs.append(pd.read_csv(os.path.join(\n",
    "        output_path, 'filtered', output), sep=';', header=None))\n",
    "\n",
    "print(frame.shape)\n",
    "frame = pd.concat([df.iloc[:, -2:] for df in dfs], sort=False)\n",
    "print(frame.groupby(list(frame.columns), as_index=False).size().to_frame(\n",
    "    'frames').reset_index().to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot density maps to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T09:18:13.363963Z",
     "start_time": "2019-09-24T09:16:59.058156Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3257f4ef1f43b69fbef5d1b068f91f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ko-240-050-240.csv\n"
     ]
    }
   ],
   "source": [
    "# save density maps\n",
    "\n",
    "image_directory = \"check/240x200/images/\"\n",
    "\n",
    "if not os.path.isdir(image_directory):\n",
    "    os.mkdir(image_directory)\n",
    "\n",
    "def filter_chunk(chunk):\n",
    "    return chunk.loc[(chunk[231] == 0.5) & (chunk[232] == 0.5)]\n",
    "    \n",
    "outputs = os.listdir(os.path.join(output_path, 'filtered'))\n",
    "for output in tqdm_notebook(outputs):\n",
    "    plot.processFile(output, os.path.join(output_path, 'filtered'), image_directory, (20,24)) # , _filter=filter_chunk\n",
    "    break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
