{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-26T14:12:14.370938Z",
     "start_time": "2019-08-26T14:11:37.748052Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - ex_logger.my_experiment - Running command 'main'\n",
      "INFO - ex_logger.my_experiment - Started run with ID \"2\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'number_of_targets': 2, 'number_of_trees': 50, 'save': False, 'seed': 421394921, 'reader': {'densitymap': {'seperator': ';', 'file_filter': <function <lambda> at 0x000001943DC8B678>}}, 'randomforest': {'regression': {}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - ex_logger.main - {'number_of_targets': 2, 'number_of_trees': 50, 'save': False, 'seed': 421394921, 'reader': {'densitymap': {'seperator': ';', 'file_filter': <function <lambda> at 0x000001943DC8B678>}}}\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-050-240_2019-06-10_19-37-23.864_filtered_reduced.csv loaded, 213 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-050-240_2019-06-28_19-17-42.661_filtered_reduced.csv loaded, 219 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-050-240_2019-06-28_19-26-52.509_filtered_reduced.csv loaded, 224 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-060-240_2019-06-10_19-38-06.167_filtered_reduced.csv loaded, 202 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-060-240_2019-06-28_19-18-23.76_filtered_reduced.csv loaded, 201 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-060-240_2019-06-28_19-27-35.805_filtered_reduced.csv loaded, 203 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-080-240_2019-06-10_19-38-44.260_filtered_reduced.csv loaded, 337 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-080-240_2019-06-28_19-19-01.83_filtered_reduced.csv loaded, 344 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-080-240_2019-06-28_19-28-16.408_filtered_reduced.csv loaded, 324 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-100-240_2019-06-10_19-39-52.891_filtered_reduced.csv loaded, 286 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-100-240_2019-06-28_19-20-11.545_filtered_reduced.csv loaded, 309 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-100-240_2019-06-28_19-29-28.361_filtered_reduced.csv loaded, 308 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-120-240_2019-06-10_19-40-51.905_filtered_reduced.csv loaded, 432 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-120-240_2019-06-28_19-21-11.141_filtered_reduced.csv loaded, 423 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-120-240_2019-06-28_19-30-30.488_filtered_reduced.csv loaded, 433 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-150-240_2019-06-10_19-42-36.540_filtered_reduced.csv loaded, 450 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-150-240_2019-06-28_19-22-59.7_filtered_reduced.csv loaded, 427 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-150-240_2019-06-28_19-32-21.415_filtered_reduced.csv loaded, 434 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-240-240_2019-04-24_17-43-58.231_filtered_reduced.csv loaded, 414 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-240-240_2019-06-28_19-24-47.252_filtered_reduced.csv loaded, 424 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/obstacle/ORG-KO-240-240-240_2019-06-28_19-34-11.853_filtered_reduced.csv loaded, 416 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/experiment/ko-240-050-240_combined_MB_filtered.csv loaded, 861 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/experiment/ko-240-060-240_combined_MB_filtered.csv loaded, 803 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/experiment/ko-240-080-240_combined_MB_filtered.csv loaded, 1064 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/experiment/ko-240-100-240_combined_MB_filtered.csv loaded, 955 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/experiment/ko-240-120-240_combined_MB_filtered.csv loaded, 1420 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/experiment/ko-240-150-240_combined_MB_filtered.csv loaded, 1364 samples, 240 features per sample, 2 targets per sample\n",
      "INFO - ex_logger.reader.densitymap.load_file - File check/csvs/experiment/ko-240-240-240_combined_MB_filtered.csv loaded, 1330 samples, 240 features per sample, 2 targets per sample\n",
      "Learning targets:   0%|                                                                          | 0/2 [00:00<?, ?it/s]INFO - ex_logger.randomforest.regression.fit - Start fitting model target-0\n",
      "INFO - ex_logger.randomforest.regression.fit - Done fitting model target-0 - 17033446000ns needed\n",
      "Learning targets:  50%|█████████████████████████████████                                 | 1/2 [00:17<00:17, 17.36s/it]INFO - ex_logger.randomforest.regression.fit - Start fitting model target-1\n",
      "INFO - ex_logger.randomforest.regression.fit - Done fitting model target-1 - 14831877200ns needed\n",
      "Learning targets: 100%|██████████████████████████████████████████████████████████████████| 2/2 [00:32<00:00, 16.70s/it]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../python/python_src_preprocessing/src'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utils.reader.densitymap import ingredient as density_ingredient, load_directory\n",
    "from rf.regression import ingredient as rf_ingredient, multiple_forests as multiple\n",
    "\n",
    "from sacred.experiment import Experiment\n",
    "from sacred.observers.file_storage import FileStorageObserver\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport utils.reader.densitymap, rf.regression\n",
    "\n",
    "%aimport utils.reader.densitymap\n",
    "\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "simulation = 'check/csvs/obstacle/'\n",
    "experiment = 'check/csvs/experiment/'\n",
    "\n",
    "ex = Experiment('my_experiment', ingredients=[density_ingredient, rf_ingredient], interactive=True)\n",
    "\n",
    "file_storage = FileStorageObserver.create('check/runs', template=os.path.abspath('check/runs/template.txt'))\n",
    "ex.observers.append(file_storage)\n",
    "\n",
    "logger = logging.getLogger('ex_logger')\n",
    "\n",
    "ch = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(levelname)s - %(name)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.handlers = []\n",
    "logger.addHandler(ch)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "ex.logger = logger\n",
    "\n",
    "@ex.config\n",
    "def config():\n",
    "    number_of_targets = 2\n",
    "    number_of_trees = 50\n",
    "    save = False\n",
    "\n",
    "@ex.main\n",
    "def main(_run, _log, _config):\n",
    "    print(_config)\n",
    "    # ex.logger.handlers = []\n",
    "    \n",
    "    file_handler = logging.FileHandler(os.path.join(file_storage.dir, 'run.log'))\n",
    "    file_handler.setFormatter(formatter)\n",
    "    ex.logger.addHandler(file_handler)\n",
    "    \n",
    "    \n",
    "    _log.info(_run.config)\n",
    "    \n",
    "    # load training (simulation data)\n",
    "    train = load_directory(simulation, _config['number_of_targets'], file_filter=lambda x: 'reduced' in x)\n",
    "\n",
    "    # load test (experiment data)\n",
    "    test = load_directory(experiment, _config['number_of_targets'], file_filter=lambda x: 'filtered' in x)\n",
    "    \n",
    "    # run\n",
    "    regressors, \\\n",
    "    normed_prediction, \\\n",
    "    (score_training, score_test, score_oob), \\\n",
    "    errors = multiple( \\\n",
    "        {'samples': train[0], 'targets': train[1]}, \\\n",
    "        {'samples': test[0], 'targets': test[1]}, \\\n",
    "    number_of_targets=_config['number_of_targets'], \\\n",
    "    number_of_trees=_config['number_of_trees'], \\\n",
    "    number_of_cores=4, \\\n",
    "    save=_config['save'])\n",
    "    \n",
    "    \n",
    "    ex.logger.removeHandler(file_handler)\n",
    "    logger.removeHandler(ch)\n",
    "    \n",
    "result = ex.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T14:30:29.284221Z",
     "start_time": "2019-08-21T14:30:29.146038Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as matplot\n",
    "import itertools\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../python/python_src_preprocessing/src'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import utils\n",
    "    \n",
    "from rf.regression import multiple_forests as multiple\n",
    "\n",
    "from utils.reader.densitymap import load_directory\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from ipywidgets import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport utils.reader.densitymap, rf.regression\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T14:30:32.685828Z",
     "start_time": "2019-08-21T14:30:32.681816Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup\n",
    "simulation = 'check/csvs/obstacle/'\n",
    "experiment = 'check/csvs/experiment/'\n",
    "\n",
    "number_of_targets = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load training (simulation data)\n",
    "train = load_directory(simulation, number_of_targets, file_filter=lambda x: 'reduced' in x)\n",
    "\n",
    "# load test (experiment data)\n",
    "test = load_directory(experiment, number_of_targets, file_filter=lambda x: 'filtered' in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "regressors, \\\n",
    "normed_prediction, \\\n",
    "(score_training, score_test, score_oob), \\\n",
    "errors = multiple( \\\n",
    "    {'samples': train[0], 'targets': train[1]}, \\\n",
    "    {'samples': test[0], 'targets': test[1]}, \\\n",
    "    number_of_trees=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T12:51:53.806263Z",
     "start_time": "2019-08-21T12:51:53.803259Z"
    }
   },
   "outputs": [],
   "source": [
    "print(result.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
